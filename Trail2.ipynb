{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "468/468 [==============================] - 165s 353ms/step - loss: 1.3388 - accuracy: 0.5439 - val_loss: 0.2571 - val_accuracy: 0.9319\n",
      "Epoch 2/20\n",
      "468/468 [==============================] - 152s 325ms/step - loss: 0.7532 - accuracy: 0.7580 - val_loss: 0.1386 - val_accuracy: 0.9617\n",
      "Epoch 3/20\n",
      "468/468 [==============================] - 153s 326ms/step - loss: 0.6149 - accuracy: 0.8004 - val_loss: 0.1251 - val_accuracy: 0.9623\n",
      "Epoch 4/20\n",
      "468/468 [==============================] - 160s 343ms/step - loss: 0.5456 - accuracy: 0.8267 - val_loss: 0.0872 - val_accuracy: 0.9758\n",
      "Epoch 5/20\n",
      "468/468 [==============================] - 158s 337ms/step - loss: 0.4986 - accuracy: 0.8411 - val_loss: 0.0923 - val_accuracy: 0.9721\n",
      "Epoch 6/20\n",
      "468/468 [==============================] - 143s 306ms/step - loss: 0.4682 - accuracy: 0.8510 - val_loss: 0.0764 - val_accuracy: 0.9779\n",
      "Epoch 7/20\n",
      "468/468 [==============================] - 143s 305ms/step - loss: 0.4334 - accuracy: 0.8634 - val_loss: 0.0694 - val_accuracy: 0.9778\n",
      "Epoch 8/20\n",
      "468/468 [==============================] - 146s 313ms/step - loss: 0.4098 - accuracy: 0.8686 - val_loss: 0.0626 - val_accuracy: 0.9816\n",
      "Epoch 9/20\n",
      "468/468 [==============================] - 142s 303ms/step - loss: 0.3909 - accuracy: 0.8774 - val_loss: 0.0702 - val_accuracy: 0.9763\n",
      "Epoch 10/20\n",
      "468/468 [==============================] - 140s 300ms/step - loss: 0.3766 - accuracy: 0.8805 - val_loss: 0.0704 - val_accuracy: 0.9784\n",
      "Epoch 11/20\n",
      "468/468 [==============================] - 142s 303ms/step - loss: 0.3688 - accuracy: 0.8842 - val_loss: 0.0500 - val_accuracy: 0.9837\n",
      "Epoch 12/20\n",
      "468/468 [==============================] - 142s 303ms/step - loss: 0.3525 - accuracy: 0.8880 - val_loss: 0.0473 - val_accuracy: 0.9846\n",
      "Epoch 13/20\n",
      "468/468 [==============================] - 139s 298ms/step - loss: 0.3399 - accuracy: 0.8938 - val_loss: 0.0578 - val_accuracy: 0.9833\n",
      "Epoch 14/20\n",
      "468/468 [==============================] - 136s 290ms/step - loss: 0.3373 - accuracy: 0.8948 - val_loss: 0.0586 - val_accuracy: 0.9816\n",
      "Epoch 15/20\n",
      "468/468 [==============================] - 137s 292ms/step - loss: 0.3286 - accuracy: 0.8960 - val_loss: 0.0593 - val_accuracy: 0.9810\n",
      "Epoch 16/20\n",
      "468/468 [==============================] - 136s 291ms/step - loss: 0.3125 - accuracy: 0.9015 - val_loss: 0.0543 - val_accuracy: 0.9839\n",
      "Epoch 17/20\n",
      "468/468 [==============================] - 139s 296ms/step - loss: 0.3046 - accuracy: 0.9054 - val_loss: 0.0690 - val_accuracy: 0.9775\n",
      "Epoch 18/20\n",
      "468/468 [==============================] - 138s 295ms/step - loss: 0.3058 - accuracy: 0.9035 - val_loss: 0.0534 - val_accuracy: 0.9830\n",
      "Epoch 19/20\n",
      "468/468 [==============================] - 138s 295ms/step - loss: 0.2960 - accuracy: 0.9073 - val_loss: 0.0535 - val_accuracy: 0.9838\n",
      "Epoch 20/20\n",
      "468/468 [==============================] - 136s 290ms/step - loss: 0.3005 - accuracy: 0.9061 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
      "Test loss: 0.054785504937171936\n",
      "Test accuracy: 0.9830999970436096\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "num_of_trainImgs = x_train.shape[0] #60000 here\n",
    "num_of_testImgs = x_test.shape[0] #10000 here\n",
    "img_width = 28\n",
    "img_height = 28\n",
    " \n",
    "x_train = x_train.reshape(x_train.shape[0], img_height, img_width, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_height, img_width, 1)\n",
    "input_shape = (img_height, img_width, 1)\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(4, 4),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.25,\n",
    "                        height_shift_range=0.25,\n",
    "                        zoom_range=.5,\n",
    "                        horizontal_flip=False)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, steps_per_epoch=len(x_train) // 128,\n",
    "                        epochs=12, verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save('trained_model5.h5')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017C885A9C80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import img_as_ubyte, img_as_uint    \n",
    "from skimage.color import rgb2gray\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = load_model('trained_model3.h5')\n",
    "\n",
    "img_original = cv2.imread(\"recog_1.png\")\n",
    "\n",
    "img_gray = rgb2gray(img_original)\n",
    "img_gray_u8 = img_as_ubyte(img_gray)\n",
    "im_gray_u16 = img_as_uint(img_gray)\n",
    "\n",
    "(thresh, im_binary) = cv2.threshold(im_gray_u16, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "img_resized = cv2.resize(im_binary,(28,28), interpolation=cv2.INTER_NEAREST_EXACT)\n",
    "im_gray_invert = 255 - img_resized\n",
    "\n",
    "#print(im_gray_invert)\n",
    "\n",
    "im_final = im_gray_invert.reshape(1,28,28,1)\n",
    "\n",
    "ans = model.predict(im_final)\n",
    "ans = np.argmax(ans,axis=1)[0]\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img_resized, interpolation = \"nearest\", cmap = plt.cm.gray_r)\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61c669b71af8a4bba1683ff9672a5a4202034dc0dad7002d4c0b008a64b431ac"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
